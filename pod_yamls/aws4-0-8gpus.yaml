apiVersion: v1
kind: Pod
metadata:
  name: aws4-0-8gpus
  labels:
    app: gpu-workstation
    node-idx: "4"
    gpu-count: "8"
spec:
  nodeSelector:
    kubernetes.io/hostname: "ip-172-31-138-243.us-west-2.compute.internal"
  containers:
  - name: workstation
    image: hchen403/cuda128-miniconda:py312
    imagePullPolicy: Always
    command: ["/bin/bash"]
    args: ["-c", "sleep infinity"]
    resources:
      requests:
        memory: "1000Gi"
        cpu: "90"
        nvidia.com/gpu: "8"
      limits:
        memory: "1Ti"
        cpu: "95"
        nvidia.com/gpu: "8"
    volumeMounts:
    - name: efs-storage
      mountPath: /home
    - name: dshm
      mountPath: /dev/shm
    env:
    - name: CUDA_VISIBLE_DEVICES
      value: "0,1,2,3,4,5,6,7"
    - name: PYTHONPATH
      value: "/home/efs/connect_to_cluster"
    workingDir: /home/efs/
    tty: true
    stdin: true
  volumes:
  - name: efs-storage
    persistentVolumeClaim:
      claimName: fsx
  - name: dshm
    emptyDir:
      medium: Memory
      sizeLimit: 64Gi
  restartPolicy: Never
