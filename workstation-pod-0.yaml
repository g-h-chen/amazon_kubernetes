apiVersion: v1
kind: Pod
metadata:
  name: workstation-pod-0
  labels:
    app: interactive-workstation
    pod-id: "0"
spec:
  containers:
  - name: workstation
    # image: nvidia/cuda:12.8.0-cudnn-devel-ubuntu22.04
    image: hchen403/cuda128-miniconda:py312
    imagePullPolicy: Always  # Always pull the latest version of the image
    command: ["/bin/bash"]
    args: ["-c", "sleep infinity"]
    resources:
      requests:
        memory: "1000Gi"
        cpu: "90"
        nvidia.com/gpu: "8"  # All 8 GPUs for maximum performance
      limits:
        memory: "1Ti"
        cpu: "95"
        nvidia.com/gpu: "8"
    volumeMounts:
    - name: efs-storage
      mountPath: /home
    - name: dshm
      mountPath: /dev/shm
    # env:
    # - name: CUDA_VISIBLE_DEVICES
    #   value: "0,1,2,3,4,5,6,7"  # All 8 GPUs for maximum performance
    # - name: PYTHONPATH
    #   value: "/home/efs/connect_to_cluster"
    workingDir: /home/efs/
    # Enable interactive use
    tty: true
    stdin: true
  volumes:
  - name: efs-storage
    persistentVolumeClaim:
      claimName: fsx
  - name: conda-env-storage
    persistentVolumeClaim:
      claimName: fsx  # Same FSx storage, different mount point
  - name: dshm
    emptyDir:
      medium: Memory
      sizeLimit: 64Gi
  restartPolicy: Never
